{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Environment Setup & Load data"],"metadata":{"id":"Q4I2VaErAZad"}},{"cell_type":"code","source":["import json\n","import re\n","import nltk\n","import spacy\n","nlp = spacy.load('en_core_web_sm')\n","nltk.download('punkt')\n","import nltk.data\n","from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkLzNlVhAcRC","executionInfo":{"status":"ok","timestamp":1666891195409,"user_tz":240,"elapsed":8702,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"}},"outputId":"92bf2948-0df1-486b-c326-715851982bf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["sentences = []\n","with open('anlp-sciner-test.txt', 'r',encoding='utf-8') as f:\n","  for line in f:\n","      sentences.append(line)\n","\n","      # save sentences with keywords in json format\n","json_object = json.dumps(sentences, indent=4)\n","with open(\"test_sentences.json\", \"w\") as outfile:\n","    outfile.write(json_object)\n","\n"],"metadata":{"id":"zII7EhPRb3r8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BIO Sequence Labeling"],"metadata":{"id":"KYhIW6aa9FhR"}},{"cell_type":"code","source":["features_list = []\n","with open('word_dict.txt','r',encoding='utf-8') as f:\n","    for line in f.readlines():\n","        features_list.append(line.strip().split(',')[0])\n","\n","\n","label_dict={}\n","with open('word_dict.txt','r',encoding='utf-8') as f:\n","     for line in f.readlines():\n","          item = line.split(',')\n","          label_dict[item[0].strip()]=item[1].strip()"],"metadata":{"id":"Ij3nA5McpnAo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def BIO_labeling(inputs,output='output'):\n","    file_output = output+'.conll'\n","    index_log = 0\n","    writen_flag=0\n","\n","    for line in inputs:\n","        # print(line)\n","        word_list = [t.text.strip() for t in nlp(line.strip())]\n","        tag_list = [\"O\" for i in range(len(word_list))]\n","    \n","\n","        for keyword in features_list:\n","            metric_flag = 0    # Check if there's metricName or hyperparameter in the sentence\n","            index_start_tag=0\n","            index_log = 0\n","            # print('Keyword: ',keyword)\n","\n","            while 1:\n","                remaining_sentence = ' '.join(word_list[index_log:])\n","                if keyword not in remaining_sentence:    # keyword does not exist in the remaining part of the sentence.\n","                    index_log = 0\n","                    break\n","\n","                # keyword exist in the remaining part of the sentence.----------------------\n","                search_word = keyword\n","                for tk in word_list[index_log:]:\n","                  if keyword in tk:    # keyword exist as a substring of one of tokens. Example BERT in VideoBERT\n","                    search_word = tk\n","                    break\n","                \n","                search_length = len(search_word.split(' '))\n","                if search_length == 1:        # If search word contains only one word\n","                    index_start_tag = word_list.index(search_word,index_log)    # locate the keyword        \n","                    index_log = index_start_tag+1                           # set the index to the next word after the located keyword \n","                else:                         # If search word contains more than one word\n","                    try:\n","                      index_start_tag = word_list.index(search_word.split(' ')[0],index_log)           \n","                      index_log = index_start_tag+search_length                       \n","                    except ValueError: break\n","\n","                # BIO labeling according to the length of the keyword and position pointer\n","                for i in range(index_start_tag, index_start_tag + search_length):\n","                    if index_start_tag == i:                # beginning of the label, mark with B-\n","\n","                        \n","                        if tag_list[i] == 'O':\n","                            tag_list[i] = \"B-\"+label_dict[keyword].replace(\"\\n\",'')\n","\n","                    else:\n","                        if tag_list[i] == 'O':\n","                            tag_list[i] = \"I-\"+label_dict[keyword].replace(\"\\n\",'')  # middle of the label, mark with I-\n","\n","                \n","                \n","                # labeling value \n","                if search_word in label_dict.keys():\n","                  if label_dict[search_word]=='HyperparameterName' or label_dict[search_word]=='MetricName':  \n","                    metric_flag=1\n","                    # print('Aha! Found {}!'.format(label_dict[search_word]))\n","                \n","\n","                for tk in word_list[index_log-1:]:\n","                  if metric_flag:    # metricName or hyperparameterName exist in the sentence, we detect pure value(integer or float) in the sentence as well.\n","                    if re.match('^\\d*(\\.\\d+)?$',tk):\n","                      try:\n","                        label_name = label_dict[search_word].split('N')[0]+'Value'    # get label name: MetricValue or HyperparameterValue\n","                        label_position = word_list.index(tk)\n","                        if tag_list[label_position] == 'O':\n","                          tag_list[label_position] = \"B-\"+label_name\n","                        break\n","                      except KeyError: continue\n","\n","        with open(file_output,'a',encoding='utf-8') as output_f:\n","            if writen_flag == 1:\n","                output_f.write('\\n')\n","            for w,t in zip(word_list,tag_list):\n","                      if w != '\t' and t != ' ':\n","                          output_f.write(w+\" \"+t+'\\n')\n","                          writen_flag=1\n","\n","        "],"metadata":{"id":"oyYc0YQmd-lo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BIO_labeling(all_sentences,'training_data')\n","\n","BIO_labeling(all_sentences,'test_with_labels')\n","\n","#BIO_labeling(all_sentences,'test_yubo')\n"],"metadata":{"id":"owEGx2F6r50K"},"execution_count":null,"outputs":[]}]}